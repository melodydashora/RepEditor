# LLM Router V2 Integration - Status Report
**Date**: October 3, 2025  
**Issue**: Circuit breaker poisoning & timeout drift  
**Solution**: GPT Pro's v2 router with proper cancellation

---

## Problem Diagnosis (GPT Pro Analysis)

### Root Causes Identified
1. **Circuit Breaker Poisoning**: Aborted requests from hedging/budget were counted as failures, tripping breakers
2. **Budget Drift**: 30s configured ‚Üí 50s elapsed due to "final sweep" past budget cap
3. **Dangling Requests**: Slow providers weren't canceled when a winner returned
4. **Hedge Storm**: 50 concurrent users multiplying calls without stagger

### Log Evidence
```
‚è±Ô∏è anthropic slow (>1200ms), racing fallbacks...
‚ùå anthropic failed: The operation was aborted.
‚ö° Circuit breaker OPEN for openai (5 failures)
üí• All LLM providers failed after 50003ms
```

---

## V2 Router Implementation

### Files Added
- ‚úÖ `server/lib/llm-router-v2.js` - New router with proper cancellation
- ‚úÖ `scripts/hedge-burst-v2.mjs` - Burst test (60 concurrent requests)
- ‚úÖ `scripts/test-v2-router.mjs` - Standalone router test

### Files Updated
- ‚úÖ `server/routes/blocks.js` - Now uses `routeLLMTextV2()`
- ‚úÖ `server/routes/health.js` - Added router diagnostics
- ‚úÖ `.env.example` - Updated timeouts and model names

### Key Improvements
1. **Error Classification**: ABORTED/TIMEOUT don't increment circuit breakers
2. **Global Budget Controller**: Single AbortController for all providers
3. **Clean Cancellation**: Winners abort all losers immediately
4. **Staggered Hedging**: +1.2s for backup start, +0.4s between backups
5. **Per-Provider Gates**: Concurrency caps (Anthropic: 10, OpenAI: 12, Gemini: 12)

---

## Test Results

### Standalone Test (Small Prompts) ‚úÖ
```bash
$ node scripts/test-v2-router.mjs
Provider: openai
Duration: 1652ms
Response: Hello from [provider name]!
Errors: [
  { provider: 'anthropic', error: 'Anthropic 404', kind: 'OTHER' },
  { provider: 'google', error: 'Gemini 404', kind: 'OTHER' }
]
```
**Status**: ‚úÖ Working - OpenAI wins race, others fail gracefully

### Production Endpoint (Large Prompts) ‚ùå
```bash
$ curl -X POST http://localhost:5000/api/blocks
ü§ñ Co-Pilot provider: none in 8008ms
üí• All LLM providers failed: [
  { provider: 'anthropic', error: 'Anthropic 404', kind: 'OTHER' },
  { provider: 'google', error: 'Gemini 404', kind: 'OTHER' },
  { provider: 'openai', error: 'abort', kind: 'OTHER' }
]
```
**Status**: ‚ùå All providers failing on full prompts

---

## Current Issues

### 1. Anthropic 404 Error
**Problem**: Model `claude-sonnet-4-5-20250929` returns 404  
**Possible Causes**:
- API key issue
- Model name typo
- Model not available in region

### 2. OpenAI Aborted
**Problem**: OpenAI gets aborted even though it wins small prompt tests  
**Theory**: Large prompt (location context) causes all providers to exceed 8s budget

### 3. Budget Too Aggressive
**Current**: 8s total budget  
**Result**: Large prompts timeout before any provider responds  
**Recommendation**: Increase to 15-20s for production prompts

---

## Next Steps

### Option A: Debug Anthropic (Recommended)
1. Test Anthropic API key directly with curl
2. Verify model name `claude-sonnet-4-5-20250929`
3. Check API quotas/limits

### Option B: Increase Budget
```env
LLM_TOTAL_BUDGET_MS=20000  # 20s instead of 8s
```
This gives providers more time for large prompts while still preventing infinite hangs.

### Option C: Simplify Prompts
Reduce location context sent to LLM to decrease token count and response time.

---

## Configuration

### Current Settings
```env
PREFERRED_MODEL=anthropic:claude-sonnet-4-5-20250929
FALLBACK_MODELS=openai:gpt-4o,google:gemini-1.5-pro

LLM_PRIMARY_TIMEOUT_MS=1200          # Hedge after 1.2s
LLM_TOTAL_BUDGET_MS=8000            # Total 8s budget
FALLBACK_HEDGE_STAGGER_MS=400        # 0.4s between backups

ANTHROPIC_MAX_CONCURRENCY=10
OPENAI_MAX_CONCURRENCY=12
GEMINI_MAX_CONCURRENCY=12

CIRCUIT_ERROR_THRESHOLD=5
CIRCUIT_COOLDOWN_MS=60000
```

### Recommended Adjustment
```env
LLM_TOTAL_BUDGET_MS=20000  # Increase for production prompts
```

---

## Summary

**What Works**: ‚úÖ V2 router with proper cancellation, error classification, hedging  
**What's Broken**: ‚ùå Anthropic 404, large prompts timeout all providers  
**Quick Fix**: Increase `LLM_TOTAL_BUDGET_MS` to 20000 and debug Anthropic key/model  

**GPT Pro's Solution**: ‚úÖ Implemented correctly - prevents circuit breaker poisoning  
**Production Status**: ‚ö†Ô∏è Needs budget tuning + Anthropic debugging
